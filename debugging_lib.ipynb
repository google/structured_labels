{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np \n",
    "from shared import weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'sigma': 5.0, 'balanced_weights': \"True\"}\n",
    "embedding = np.float32(np.random.normal(0, 1, (10, 3)))\n",
    "main_labels = np.float32(np.random.binomial(1, 0.5, (10, 1)))\n",
    "auxiliary_labels = np.float32(np.random.binomial(1, 0.5, (10, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, weights_pos, weights_neg = weighting.get_weights(main_labels,\n",
    "\t\t\tauxiliary_labels, balanced=params['balanced_weights'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_label_pos = tf.reduce_mean(main_labels) * main_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[0.  ],\n",
       "       [0.  ],\n",
       "       [0.  ],\n",
       "       [0.  ],\n",
       "       [0.  ],\n",
       "       [0.56],\n",
       "       [0.56],\n",
       "       [0.  ],\n",
       "       [0.56],\n",
       "       [0.56]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.divide_no_nan(main_label_pos, weights_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mmd_loss_weighted(embedding, main_labels, auxiliary_labels, params, dummy):\n",
    "\tr\"\"\"Computes MMD loss between embeddings of groups defined by label.\n",
    "\n",
    "\tMaximum Mean Discrepancy (MMD) is an integrated probability metric.\n",
    "\tIt measures the distance between two probability distributions. In this\n",
    "\tsetting, we measure (and penalize) the distance between the probability\n",
    "\tdistributions of the embeddings of group 0 (where auxiliary_labels ==0), and\n",
    "\tthe emeddings of group 1 (where auxiliary_labels ==1). The specific equation\n",
    "\tfor computing the MMD is:\n",
    "\n",
    "\tMMD^2(P, Q)= || \\E{\\phi_sigma(x)} - \\E{\\phi_sigma(y)} ||^2\n",
    "\t\t\t\t\t\t= \\E{ K_sigma(x, x) } + \\E{ K_sigma(y, y) } - 2 \\E{ K_sigma(x, y)},\n",
    "\n",
    "\twhere K_sigma = <\\phi_sigma(x), \\phi_sigma(y)>,is a kernel function,\n",
    "\tin this case a radial basis kernel, with bandwidth sigma.\n",
    "\n",
    "\tFor our main approach, we penalize the mmd_loss (encourage the distance to be\n",
    "\tsmall i.e., encourage the two distributions to be close, which is roughly\n",
    "\tequivalent to an adversarial setting: by forcing MMD to be small, an\n",
    "\tadversary cannot distinguish between the two groups solely based on the\n",
    "\tembedding. This also implies that cross-prediction (predicting\n",
    "\tauxiliary_labels using embedding) is penalized\n",
    "\n",
    "\tArgs:\n",
    "\t\tembedding: tensor with learned embedding\n",
    "\t\tmain_labels: tensor with main labels\n",
    "\t\tauxiliary_labels: tensor with label defining 2 groups\n",
    "\t\tsigma: scalar, bandwidth for kernel used to compute MMD\n",
    "\tReturns:\n",
    "\t\tMMD between embeddings of the two groups defined by label\n",
    "\t\"\"\"\n",
    "\tsigma = params['sigma']\n",
    "\n",
    "\tkernel_mat = tfa.losses.metric_learning.pairwise_distance(embedding,\n",
    "\t\tsquared=True)\n",
    "\tkernel_mat = tf.math.exp((- kernel_mat) / 2* sigma**2)\n",
    "\tif dummy:\n",
    "\t\tweights_pos = np.float32(np.ones((10,1)))\n",
    "\t\tweights_neg = np.float32(np.ones((10,1)))\n",
    "\n",
    "\telse:\n",
    "\t\t_, weights_pos, weights_neg = weighting.get_weights(main_labels,\n",
    "\t\t\tauxiliary_labels, balanced=params['balanced_weights'])\n",
    "\n",
    "\tif len(auxiliary_labels.shape) == 1:\n",
    "\t\tauxiliary_labels = tf.expand_dims(auxiliary_labels, axis=-1)\n",
    "\n",
    "\tpos_mask = tf.matmul(auxiliary_labels, tf.transpose(auxiliary_labels))\n",
    "\tneg_mask = tf.matmul(1.0 - auxiliary_labels,\n",
    "\t\ttf.transpose(1.0 - auxiliary_labels))\n",
    "\tpos_neg_mask = tf.matmul(auxiliary_labels,\n",
    "\t\ttf.transpose(1.0 - auxiliary_labels))\n",
    "\tneg_pos_mask = tf.matmul((1.0 - auxiliary_labels),\n",
    "\t\ttf.transpose(auxiliary_labels))\n",
    "\n",
    "\tpos_kernel_mean = kernel_mat * pos_mask\n",
    "\tpos_kernel_mean = tf.math.divide_no_nan(\n",
    "\t\ttf.reduce_sum(pos_kernel_mean, axis=1),\n",
    "\t\ttf.reduce_sum(pos_mask, axis=1))\n",
    "\tpos_kernel_mean = tf.math.divide_no_nan(\n",
    "\t\ttf.reduce_sum(pos_kernel_mean * weights_pos),\n",
    "\t\ttf.reduce_sum(weights_pos) * 2* sigma**2)\n",
    "\n",
    "\tneg_kernel_mean = kernel_mat * neg_mask\n",
    "\tneg_kernel_mean = tf.math.divide_no_nan(\n",
    "\t\ttf.reduce_sum(neg_kernel_mean, axis=1),\n",
    "\t\ttf.reduce_sum(neg_mask, axis=1))\n",
    "\tneg_kernel_mean = tf.math.divide_no_nan(\n",
    "\t\ttf.reduce_sum(neg_kernel_mean * weights_neg),\n",
    "\t\ttf.reduce_sum(weights_neg) * 2* sigma**2)\n",
    "\n",
    "\tneg_pos_kernel_mean = kernel_mat * neg_pos_mask\n",
    "\tneg_pos_kernel_mean = tf.math.divide_no_nan(\n",
    "\t\ttf.reduce_sum(neg_pos_kernel_mean, axis=1),\n",
    "\t\ttf.reduce_sum(neg_pos_mask, axis=1))\n",
    "\tneg_pos_kernel_mean = tf.math.divide_no_nan(\n",
    "\t\ttf.reduce_sum(neg_pos_kernel_mean * weights_neg),\n",
    "\t\ttf.reduce_sum(weights_neg) * 2* sigma**2)\n",
    "\n",
    "\tpos_neg_kernel_mean = kernel_mat * pos_neg_mask\n",
    "\tpos_neg_kernel_mean = tf.math.divide_no_nan(\n",
    "\t\ttf.reduce_sum(pos_neg_kernel_mean, axis=1),\n",
    "\t\ttf.reduce_sum(pos_neg_mask, axis=1))\n",
    "\tpos_neg_kernel_mean = tf.math.divide_no_nan(\n",
    "\t\ttf.reduce_sum(pos_neg_kernel_mean * weights_pos),\n",
    "\t\ttf.reduce_sum(weights_pos) * 2* sigma**2)\n",
    "\n",
    "\tmmd_val = pos_kernel_mean + neg_kernel_mean - (\n",
    "\t\tpos_neg_kernel_mean + neg_pos_kernel_mean)\n",
    "\tmmd_val = tf.maximum(0.0, mmd_val)\n",
    "\n",
    "\treturn mmd_val, pos_kernel_mean, neg_kernel_mean, neg_pos_kernel_mean, pos_neg_kernel_mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mmd_loss_unweighted(embedding, auxiliary_labels, params):\n",
    "\tr\"\"\"Computes MMD loss between embeddings of groups defined by label.\n",
    "\n",
    "\tMaximum Mean Discrepancy (MMD) is an integrated probability metric.\n",
    "\tIt measures the distance between two probability distributions. In this\n",
    "\tsetting, we measure (and penalize) the distance between the probability\n",
    "\tdistributions of the embeddings of group 0 (where auxiliary_labels ==0), and\n",
    "\tthe emeddings of group 1 (where auxiliary_labels ==1). The specific equation\n",
    "\tfor computing the MMD is:\n",
    "\n",
    "\tMMD^2(P, Q)= || \\E{\\phi_sigma(x)} - \\E{\\phi_sigma(y)} ||^2\n",
    "\t\t\t\t\t\t= \\E{ K_sigma(x, x) } + \\E{ K_sigma(y, y) } - 2 \\E{ K_sigma(x, y)},\n",
    "\n",
    "\twhere K_sigma = <\\phi_sigma(x), \\phi_sigma(y)>,is a kernel function,\n",
    "\tin this case a radial basis kernel, with bandwidth sigma.\n",
    "\n",
    "\tFor our main approach, we penalize the mmd_loss (encourage the distance to be\n",
    "\tsmall i.e., encourage the two distributions to be close, which is roughly\n",
    "\tequivalent to an adversarial setting: by forcing MMD to be small, an\n",
    "\tadversary cannot distinguish between the two groups solely based on the\n",
    "\tembedding. This also implies that cross-prediction (predicting\n",
    "\tauxiliary_labels using embedding) is penalized.\n",
    "\n",
    "\tArgs:\n",
    "\t\tembedding: tensor with learned embedding\n",
    "\t\tauxiliary_labels: tensor with label defining 2 groups\n",
    "\t\tsigma: scalar, bandwidth for kernel used to compute MMD\n",
    "\tReturns:\n",
    "\t\tMMD between embeddings of the two groups defined by label\n",
    "\t\"\"\"\n",
    "\tsigma = params['sigma']\n",
    "\tdel params\n",
    "\n",
    "\tkernel = tfp.math.psd_kernels.ExponentiatedQuadratic(\n",
    "\t\tamplitude=1.0, length_scale=sigma)\n",
    "\n",
    "\tkernel_mat = kernel.matrix(embedding, embedding)\n",
    "\n",
    "\tif len(auxiliary_labels.shape) == 1:\n",
    "\t\tauxiliary_labels = tf.expand_dims(auxiliary_labels, axis=-1)\n",
    "\n",
    "\tpos_mask = tf.matmul(auxiliary_labels, tf.transpose(auxiliary_labels))\n",
    "\tneg_mask = tf.matmul(1.0 - auxiliary_labels,\n",
    "\t\ttf.transpose(1.0 - auxiliary_labels))\n",
    "\tpos_neg_mask = tf.matmul(auxiliary_labels,\n",
    "\t\ttf.transpose(1.0 - auxiliary_labels))\n",
    "\n",
    "\tpos_kernel_mean = tf.math.divide_no_nan(\n",
    "\t\ttf.reduce_sum(pos_mask * kernel_mat), tf.reduce_sum(pos_mask))\n",
    "\tneg_kernel_mean = tf.math.divide_no_nan(\n",
    "\t\ttf.reduce_sum(neg_mask * kernel_mat), tf.reduce_sum(neg_mask))\n",
    "\tpos_neg_kernel_mean = tf.math.divide_no_nan(\n",
    "\t\ttf.reduce_sum(pos_neg_mask * kernel_mat), tf.reduce_sum(pos_neg_mask))\n",
    "\n",
    "\tmmd_val = pos_kernel_mean + neg_kernel_mean - 2 * pos_neg_kernel_mean\n",
    "\tmmd_val = tf.maximum(0.0, mmd_val)\n",
    "\n",
    "\treturn mmd_val, pos_kernel_mean, neg_kernel_mean, pos_neg_kernel_mean, pos_neg_kernel_mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmd_loss_weighted2(embedding, main_labels, auxiliary_labels, params, dummy):\n",
    "\tr\"\"\"Computes MMD loss between embeddings of groups defined by label.\n",
    "\n",
    "\tMaximum Mean Discrepancy (MMD) is an integrated probability metric.\n",
    "\tIt measures the distance between two probability distributions. In this\n",
    "\tsetting, we measure (and penalize) the distance between the probability\n",
    "\tdistributions of the embeddings of group 0 (where auxiliary_labels ==0), and\n",
    "\tthe emeddings of group 1 (where auxiliary_labels ==1). The specific equation\n",
    "\tfor computing the MMD is:\n",
    "\n",
    "\tMMD^2(P, Q)= || \\E{\\phi_sigma(x)} - \\E{\\phi_sigma(y)} ||^2\n",
    "\t\t\t\t\t\t= \\E{ K_sigma(x, x) } + \\E{ K_sigma(y, y) } - 2 \\E{ K_sigma(x, y)},\n",
    "\n",
    "\twhere K_sigma = <\\phi_sigma(x), \\phi_sigma(y)>,is a kernel function,\n",
    "\tin this case a radial basis kernel, with bandwidth sigma.\n",
    "\n",
    "\tFor our main approach, we penalize the mmd_loss (encourage the distance to be\n",
    "\tsmall i.e., encourage the two distributions to be close, which is roughly\n",
    "\tequivalent to an adversarial setting: by forcing MMD to be small, an\n",
    "\tadversary cannot distinguish between the two groups solely based on the\n",
    "\tembedding. This also implies that cross-prediction (predicting\n",
    "\tauxiliary_labels using embedding) is penalized.\n",
    "\n",
    "\tArgs:\n",
    "\t\tembedding: tensor with learned embedding\n",
    "\t\tauxiliary_labels: tensor with label defining 2 groups\n",
    "\t\tsigma: scalar, bandwidth for kernel used to compute MMD\n",
    "\tReturns:\n",
    "\t\tMMD between embeddings of the two groups defined by label\n",
    "\t\"\"\"\n",
    "\tsigma = params['sigma']\n",
    "\tkernel = tfp.math.psd_kernels.ExponentiatedQuadratic(\n",
    "\t\tamplitude=1.0, length_scale=sigma)\n",
    "\n",
    "\tkernel_mat = kernel.matrix(embedding, embedding)\n",
    "\n",
    "\tif len(auxiliary_labels.shape) == 1:\n",
    "\t\tauxiliary_labels = tf.expand_dims(auxiliary_labels, axis=-1)\n",
    "\tif dummy:\n",
    "\t\tweights_pos = auxiliary_labels\n",
    "\t\tweights_neg = 1.0 - auxiliary_labels\n",
    "\n",
    "\telse:\n",
    "\t\t_, weights_pos, weights_neg = weighting.get_weights(main_labels,\n",
    "\t\t\tauxiliary_labels, balanced=params['balanced_weights'])\n",
    "        \n",
    "\tpos_mask = tf.matmul(auxiliary_labels, tf.transpose(auxiliary_labels))\n",
    "\tneg_mask = tf.matmul(1.0 - auxiliary_labels,\n",
    "\t\ttf.transpose(1.0 - auxiliary_labels))\n",
    "\tpos_neg_mask = tf.matmul(auxiliary_labels,\n",
    "\t\ttf.transpose(1.0 - auxiliary_labels))\n",
    "\tneg_pos_mask = tf.matmul((1.0 - auxiliary_labels),\n",
    "\t\ttf.transpose(auxiliary_labels))\n",
    "\n",
    "\tpos_kernel_mean = kernel_mat * pos_mask\n",
    "\tpos_kernel_mean = tf.math.divide_no_nan(\n",
    "\t\ttf.reduce_sum(pos_kernel_mean, axis=1),\n",
    "\t\ttf.reduce_sum(pos_mask, axis=1))\n",
    "\tpos_kernel_mean = tf.math.divide_no_nan(\n",
    "\t\ttf.reduce_sum(pos_kernel_mean * tf.squeeze(weights_pos)),\n",
    "\t\ttf.reduce_sum(weights_pos))\n",
    "    \n",
    "\tneg_kernel_mean = kernel_mat * neg_mask\n",
    "\tneg_kernel_mean = tf.math.divide_no_nan(\n",
    "\t\ttf.reduce_sum(neg_kernel_mean, axis=1),\n",
    "\t\ttf.reduce_sum(neg_mask, axis=1))\n",
    "\tneg_kernel_mean = tf.math.divide_no_nan(\n",
    "\t\ttf.reduce_sum(neg_kernel_mean * tf.squeeze(weights_neg)),\n",
    "\t\ttf.reduce_sum(weights_neg))\n",
    "\n",
    "\tneg_pos_kernel_mean = kernel_mat * neg_pos_mask\n",
    "\tneg_pos_kernel_mean = tf.math.divide_no_nan(\n",
    "\t\ttf.reduce_sum(neg_pos_kernel_mean, axis=1),\n",
    "\t\ttf.reduce_sum(neg_pos_mask, axis=1))\n",
    "\tneg_pos_kernel_mean = tf.math.divide_no_nan(\n",
    "\t\ttf.reduce_sum(neg_pos_kernel_mean * tf.squeeze(weights_neg)),\n",
    "\t\ttf.reduce_sum(weights_neg))\n",
    "\n",
    "\tpos_neg_kernel_mean = kernel_mat * pos_neg_mask\n",
    "\tpos_neg_kernel_mean = tf.math.divide_no_nan(\n",
    "\t\ttf.reduce_sum(pos_neg_kernel_mean, axis=1),\n",
    "\t\ttf.reduce_sum(pos_neg_mask, axis=1))\n",
    "\tpos_neg_kernel_mean = tf.math.divide_no_nan(\n",
    "\t\ttf.reduce_sum(pos_neg_kernel_mean * tf.squeeze(weights_pos)),\n",
    "\t\ttf.reduce_sum(weights_pos))\n",
    "\n",
    "\tmmd_val = pos_kernel_mean + neg_kernel_mean - (\n",
    "\t\tpos_neg_kernel_mean + neg_pos_kernel_mean)\n",
    "\tmmd_val = tf.maximum(0.0, mmd_val)\n",
    "\n",
    "\treturn mmd_val, pos_kernel_mean, neg_kernel_mean, pos_neg_kernel_mean, pos_neg_kernel_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "uw_mmd = mmd_loss_unweighted(embedding, auxiliary_labels, params)\n",
    "# wd_mmd = mmd_loss_weighted(embedding, main_labels, auxiliary_labels, params, True)\n",
    "# wnd_mmd = mmd_loss_weighted(embedding, main_labels, auxiliary_labels, params, False)\n",
    "w2d_mmd = mmd_loss_weighted2(embedding, main_labels, auxiliary_labels, params, True)\n",
    "w2nd_mmd = mmd_loss_weighted2(embedding, main_labels, auxiliary_labels, params, False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.045209646>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.8775899>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9357638>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.884072>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.884072>)"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uw_mmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wd_mmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wnd_mmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.045209646>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.8775899>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9357638>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.884072>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.884072>)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2d_mmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.045209765>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.8775899>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9357638>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.884072>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.884072>)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2nd_mmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, weights_pos, weights_neg = weighting.get_weights(main_labels,\n",
    "\tauxiliary_labels, balanced=params['balanced_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.99999920236092"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5.2655387/0.8775899"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[1.3333334],\n",
       "       [0.       ],\n",
       "       [0.       ],\n",
       "       [0.       ],\n",
       "       [0.       ],\n",
       "       [1.3333334],\n",
       "       [0.       ],\n",
       "       [0.       ],\n",
       "       [4.       ],\n",
       "       [1.3333334]], dtype=float32)>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=12.0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(weights_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[3, 5], [7, 11]], dtype=tf.int32)\n",
    "a = tf.constant([[4, 8]], dtype=tf.int32)\n",
    "y = a * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[12, 40],\n",
       "       [28, 88]], dtype=int32)>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auxiliary_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_auxiliary_labels = tf.expand_dims(auxiliary_labels, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 10, 10])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tf_auxiliary_labels * tf.transpose(tf_auxiliary_labels) * kernel_mat).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
